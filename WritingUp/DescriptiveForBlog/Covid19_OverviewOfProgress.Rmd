---
title: "Covid-19: Scoping the field"
author: "Orestis, Lio"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2: 
    toc : true
    toc_float : true
editor_options: 
  chunk_output_type: console
---

```{r echo = FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, fig.height = 6, fig.width = 12)

library(tidyverse)
library(countrycode)
library(stringr)
library(lmerTest)
library(stargazer)
library(mfx)
library(knitr)
library(kSamples)
library(FSA)
library(kableExtra)
library(xtable)
library(miceadds)
library(jtools)
library(plm)
library(clubSandwich)
library(ggrepel)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(naniar)
library(ggpubr)
library(lubridate)
library(ggmap)
library(tufte)

options("jtools-digits" = 4,scipen=999) # set displayed decimal places to 4






rm(list = ls())



gwmp<-readRDS("gwmp.rds")

gwmp$continent <- countrycode(sourcevar = gwmp$Country,
                            origin = "country.name",
                            destination = "continent")


gwmp<-gwmp%>%
  #dplyr::arrange(Date)%>%
  group_by(Country)%>%
  mutate(New_cases = ConfirmedCases - dplyr::lag(ConfirmedCases))%>%
  mutate(New_deaths = ConfirmedCases - dplyr::lag(ConfirmedDeaths))%>%
  ungroup()
  

city_short<-gwmp%>%
  filter(!is.na(Movement),!is.na(risktaking),!is.na(Temp_C))%>%
  group_by(Country,City)%>%
  summarise(
    TotalCases=mean(ConfirmedCases,na.rm=T),
    TotalDeaths=mean(ConfirmedDeaths,na.rm=T),
    Population=mean(population),
    COL=first(COL),
    Mobility=mean(Movement),
    SI=mean(StringencyIndex.x),
    Cnet=mean(index_med_est),
    Risk=first(risktaking),
    Altruism=first(altruism),
    Patience=first(patience),
     across(where(is.factor), first),
     across(where(is.character), first),
     n = n())

country_short<-gwmp%>%
  filter(!is.na(Movement),!is.na(risktaking),!is.na(Temp_C))%>%
  group_by(Country)%>%
   summarise(
     TotalCases=mean(ConfirmedCases,na.rm=T),
    TotalDeaths=mean(ConfirmedDeaths,na.rm=T),
      Population=mean(population),

    COL=first(COL),
    Mobility=mean(Movement),
    SI=mean(StringencyIndex.x),
    Cnet=mean(index_med_est),
    Risk=first(risktaking),
    Altruism=first(altruism),
    Patience=first(patience),
     across(where(is.factor), first),
     across(where(is.character), first),
     n = n())
  


```

# Data controls

Quickly checking if our data set: gwmp is integrated properly: `r summary(gwmp$StringencyIndex.x-gwmp$StringencyIndex.y)`.
Looks fine to me. We should perform later on more check ups. Like: 

1. Are the number of cases (taken from Oxford's dataset which in turn is taken from...?) in agreement with other sources. 
2. Some more random weather checks. 
3. ...

# Introduction


 $\color{blue}{\text{ When you see text in blue, this is me (Orestis) commenting. You can comment in green.}}$ 
  $\color{blue}{\text{ Oh, and let's please find a better way of commenting. This absolutely sucks.}}$ 





> The ultimate measure of a man is not where he stands in moments of comfort and convenience, but where he stands at times of challenge and controversy.
`r tufte::quote_footer('---  Martin Luther King')`


Our goal in this project is to construct a new behavioural measure of 'compliance'. 
Unlike most other behavioural approaches that elicit such measures with experimental procedures, our approach is to derive this measure from data capturing real-life responses. 
We treat Covid-19 as an exogenous shock that allows us to track real-world behaviour, namely, responsiveness to Policy (but also, to each country's respective urgency).
The high-stakes (life or death) of the situation and the attention it has received world-wide make this index all the more meaningful.
Identifying this behavioural measure and its cross-regional heterogeneity has potentially immediate policy implications. 
At the time when these lines are written: `r format(Sys.time(), '%d %B, %Y')` , the world is experiencing a resurgence of total cases infected. 
A combination of factors such as colder and dumper weather making outdoors gatherings harder and re-opening of schools is likely to reinforce this trend. 




```{r}
gwmp%>%
  filter(!is.na(New_cases))%>%
  group_by(continent,week)%>%
  summarise(newCases=mean(New_cases))%>%
  mutate(label = if_else(week == max(week,na.rm=T), as.character(continent), NA_character_)) %>%

  ggplot(aes(x = week, y = newCases, color=continent)) + 
  geom_line(size=1) +
  #scale_colour_brewer(palette = 'Set1')+
  #guides(colour="legend")
 
  scale_color_discrete(guide = FALSE)+
  
  
   theme_minimal()+
  theme(text = element_text(size=15))+
  geom_label_repel(aes(label = label),
                  nudge_x = 1,
                  na.rm = TRUE)
  


```

$\color{blue}{\text{ We need to a) extend the observation period to September}}$ 

$\color{blue}{\text{ b) cross-validate the total cases data (and total new cases that I constructed from first differences) with another data set. Currently I took those from Oxford.}}$


Should governments initiate a second wave of restrictive policies, it is worth asking the question: how effective will their policies be? 
We conjecture that the answer to this question depends by and large on citizens' compliance to these governmental mandates. 


Recent anlyses have suggested that there are benefits to be harnessed by using behavioural measures elicited cross-culturally in the past. 
For example (cite the LSE article: [https://blogs.lse.ac.uk/businessreview/2020/04/22/long-read-cultural-evolution-covid-19-and-preparing-for-whats-next/]) :

```{r COLTD, fig.cap="Collectivism by Total Death"}
country_short%>%
  filter(TotalDeaths>0)%>%
  mutate(DeathNorm=scale(TotalDeaths))%>%
  #mutate(COL=100-IDV)%>%
  ggscatterhist(x="COL", y="DeathNorm",
              #size = "Population.density",
              #color = "blacl",
              #shape = 1,
              label = "Country",
              repel = T,
              add = "reg.line",
              add.params = list(fill = "lightgray"),
              conf.int = TRUE,
              cor.coef = TRUE,
              fullrange = TRUE,
              cor.coeff.args = list(method = "pearson", label.x = -3.5, label.y = .3, label.sep = "\n", size = 6),
              xlab = "Collectivism",
              margin.params = list(fill = "lightgray")
              
)

```

$\color{blue}{\text{ This is a replication using our data. We want to divide with population to replicate more appropriately. }}$ 
$\color{blue}{\text{ But we are currently missing information on population on a lot of countries.}}$ 


```{r COLTC, fig.cap="Collectivism by Total Cases"}
country_short%>%
  filter(TotalCases>0)%>%
  mutate(CaseNorm=scale(TotalCases))%>%
  #mutate(COL=100-IDV)%>%
  ggscatterhist(x="COL", y="CaseNorm",
              #size = "Population.density",
              #color = "blacl",
              #shape = 1,
              label = "Country",
              repel = T,
              add = "reg.line",
              add.params = list(fill = "lightgray"),
              conf.int = TRUE,
              cor.coef = TRUE,
              fullrange = TRUE,
              cor.coeff.args = list(method = "pearson", label.x = -3.5, label.y = .3, label.sep = "\n", size = 6),
              xlab = "Collectivism",
              margin.params = list(fill = "lightgray")
              
)

```

Maybe mention that although collectivism correlates highly with GDP, there is still some unexplained variation. 

# Key variables


Just as every empirical scientific endeavor, the researcher faces the challenge of transitioning from the latent to the observable to the convincing. 
In our case, the latent variable of interest is that of compliance to policies that aim to reduce the virus' spread.
We construct this measure by measuring the impact of governmental policies on people's behaviour. 

Thanks to the datasets of Oxford and Coronanet, we are able to use an integrated measure of stringency, defined at a country level. 
Thanks to Google's initiative to publicize anonymized data on mobility, we can track changes in movement. 





## Stringency Index

This derived from a quantitative integration of governmental responses to the the pandemic. 




### Oxford


  $\color{blue}{\text{ I normalize the score to be in the same scale between Cnet and Oxf.}}$ 



```{r}
gwmp%>%
  filter(!is.na(StringencyIndex.x))%>%
  mutate(Oxford_norm=scale(StringencyIndex.x))%>%
  group_by(continent, week)%>%
  summarise(Oxford_Stringency_norm=mean(Oxford_norm))%>%
  mutate(label = if_else(week == max(week,na.rm=T), as.character(continent), NA_character_)) %>%

  ggplot(aes(x = week, y = Oxford_Stringency_norm, color=continent)) + 
  geom_line(size=1) +
  #scale_colour_brewer(palette = 'Set1')+
  #guides(colour="legend")
 
  scale_color_discrete(guide = FALSE)+
  
  
   theme_minimal()+
  theme(text = element_text(size=15))+
  geom_label_repel(aes(label = label),
                  nudge_x = 1,
                  na.rm = TRUE)
  
  

```






### Coronanet

```{r}
gwmp%>%
  filter(!is.na(index_med_est))%>%
  mutate(Coronanet_norm=scale(index_med_est))%>%
  group_by(continent, week)%>%
  summarise(Coronanet_Strigency_norm=mean(Coronanet_norm))%>%
  mutate(label = if_else(week == max(week,na.rm=T), as.character(continent), NA_character_)) %>%

  ggplot(aes(x = week, y = Coronanet_Strigency_norm, color=continent)) + 
  geom_line(size=1) +
  #scale_colour_brewer(palette = 'Set1')+
  #guides(colour="legend")
 
  scale_color_discrete(guide = FALSE)+
  
  
   theme_minimal()+
  theme(text = element_text(size=15))+
  geom_label_repel(aes(label = label),
                  nudge_x = 1,
                  na.rm = TRUE)
  
  

```


  $\color{blue}{\text{ Yeah.. coronanet doesn't capture any relaxation of stringency around May. We should talk to them about this.}}$ 




## Movement

Describe Google's mobility reports. 

```{r}
gwmp%>%
  filter(!is.na(Movement))%>%
  group_by(continent, week)%>%
  summarise(Mobility=mean(Movement))%>%
  mutate(label = if_else(week == max(week,na.rm=T), as.character(continent), NA_character_)) %>%

  ggplot(aes(x = week, y = Mobility, color=continent)) + 
  geom_line(size=1) +
  #scale_colour_brewer(palette = 'Set1')+
  #guides(colour="legend")
 
  scale_color_discrete(guide = FALSE)+
  
  
   theme_minimal()+
  theme(text = element_text(size=15))+
  geom_label_repel(aes(label = label),
                  nudge_x = 1,
                  na.rm = TRUE)
  
  

```

Mobility trends seem to correspond well with Oxford's data set. 

# Some tables and graphs

Notice how I round the digits now from the table.

```{r}
DT::datatable(
  city_short%>%
    dplyr::select(Country,City,Temp_C,risktaking, patience, Movement, population,n)
   
)%>%  
  DT::formatRound(columns=c('Temp_C','risktaking','patience','Movement'),digits=3)
  

```


# Missing variables: Weather

We need to find a way to cite. 

Going more granular: city level analysis. 

Increasing the level of our data-granularity is a good thing. 
Even if we cluster errors at the country-level, we still get a boost on power. 
Moreover, it does not matter if we do not get city-level data for all variables of interest. 
For example, @alfaro2020social, use city-level mobility data but country-level death and total cases data. 
We probably should do the same. 


On the map:

```{r}
qmplot(lon, lat, data = city_short, maptype = "toner-lite", color = I("red"))

```
