---
title: "Some exploration of Oxford Policy Response Database"
author: "Lio, Orestis"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2: 
    toc : true
    toc_float : true
editor_options: 
  chunk_output_type: console
  
---

<style>
p.caption {
  font-size: 0.9em;
  font-style: italic;
  color: grey;
  margin-right: 10%;
  margin-left: 10%;  
  text-align: center;
}
</style>



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)



knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
source("LR_import-data.R")

library("ggpubr")
library("dLagM")
library("DT")
library("here")
```



# Estimating compliance using ARDL model

What follows is based on ARDL estimates, which is nothing but OLS where x (here: Movement) is explained with lags of x itself, as well as present values and lagged values of y (here: Stringency). Based on the obtained coefficients, it is easy to compute the 'long run effect' of y on x, taking into account the feedback mechanisms that take place.

This should be a better way of quantifying 'compliance', as we don't have to make strong assumptions about which lag to use etc., and should some lag be more relevant than in others, this will not cause any issues.

Note that I am looking at differenced variables, as otherwise non-stationarity / spurious regression would certainly be an issue.

For example, the results for Zimbabwe read (*output seems to come out twice, don't know why):

```{r ardl, echo=FALSE}
# ARDL ----
df.ARDL <- df.use %>%
  group_by(Country) %>%
  mutate(diff.Movement = c(NA, diff(Movement)),
         diff.StringencyIndex = c(NA, diff(StringencyIndex))) %>%
  dplyr::select(Country, Date, diff.Movement, diff.StringencyIndex) %>%
  drop_na()

lr.coeffs <- data.frame(Country = unique(df.ARDL$Country),
                        LongRunCoeff = NA)
# Prepare data
for (ctry in unique(df.ARDL$Country)) {

df.now <- df.ARDL %>%
  filter(Country == ctry)

# Run estimation
p.ardl <- 3 # Lags of independent variable
q.ardl <- 3 # Autoregressive lags
model.ardl <- ardlDlm(formula = diff.Movement ~ diff.StringencyIndex, 
                      data = df.now,
                      p = p.ardl , q = q.ardl)
# Long run parameter
lr.coefficient.ardl <- sum(model.ardl$model$coefficients[2:5]) /
  (1-sum(model.ardl$model$coefficients[6:8]))

lr.coeffs$LongRunCoeff[which(lr.coeffs$Country == ctry)] <- lr.coefficient.ardl
}

summary(model.ardl)

#rm(df.now, df.ARDL, model.ardl, ctry, lr.coefficient.ardl,p.ardl,q.ardl)
```
From these coefficients, the long-run effect can be derived using the formula sum([coefficients of y])/(1-sum(coefficients of x)). For Zim, this is -1.052: A 1 unit increase in stringency will lead to a 1.052% decrease in Movement, in the long run.

The table below show coefficients for all countries, as well as by continent and geographical region. Low numbers mean high compliance.

```{r coeff graphs, echo=FALSE,  fig.height = 10}

# See if there's something going on with the coefficients
lr.coeffs.covariates <- lr.coeffs %>%
  left_join(df.use) %>%
  dplyr::select(Country, LongRunCoeff, polity2, risktaking, 
                patience, ROL, GDP.capita, CaseLog,
                Continent, Region) %>%
  fill(polity2, risktaking, patience, ROL, GDP.capita, CaseLog, 
       Continent, Region, .direction = "updown") %>%
  distinct(Country, LongRunCoeff, polity2, risktaking, patience, ROL, GDP.capita, CaseLog,
           Continent, Region) %>%
  group_by(Country) %>%
  filter(row_number()==n())

df.coeffs.reorder <- lr.coeffs.covariates %>%
  ungroup() %>%
  mutate(Country = forcats::fct_reorder(Country, LongRunCoeff))

datatable(lr.coeffs.covariates)


```

# ARDL vs. simple correlation coefficient

```{r echo = FALSE, message=FALSE, warning=FALSE}
df<-read.csv(here("df_covid_long.csv"))%>%
  filter(!is.na(StringencyIndex))%>%
  mutate(Movement_lag_1d=dplyr::lag(Movement,1))%>%
  mutate(Movement_lead_1d=dplyr::lead(Movement,1))%>%
  mutate(DifMove=Movement-Movement_lag_1d)%>%
  mutate(DifMoveLag=dplyr::lag(DifMove,1))%>%
  mutate(DifPol=StringencyIndex-dplyr::lag(StringencyIndex,1))



df$ID<-1:nrow(df)


OxVars<-c('C1_School.closing', 'C1_Flag', 'C2_Workplace.closing','C2_Flag','C3_Cancel.public.events','C3_Flag','C4_Restrictions.on.gatherings','C4_Flag','C5_Close.public.transport','C6_Stay.at.home.requirements','C6_Flag','C7_Restrictions.on.internal.movement','C7_Flag,C8_International.travel.controls','H1_Public.information.campaigns','H1_Flag')

GoogleVars<-c('retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline','Movement')


dfl<-reshape(df, idvar="ID",
                      varying = list(c(GoogleVars,'StringencyIndex')),
                                      
                      v.names = 'Value', 
                      timevar='Type',
                      times=c(GoogleVars,'StringencyIndex'),
                      
                      direction = "long")%>%
 # dplyr::select(Country,Continent,Date,Value,Type)%>%
  mutate(Date=ymd(Date))




k<-df%>%
  dplyr::select(ID, StringencyIndex)

dfl<-merge(dfl,k,by="ID")%>%
  arrange(Country,Date,Type)%>%
  mutate(Value_lag_1d=dplyr::lag(Value,1))

df_short<-df%>%
  #na.omit() %>%
  filter(!is.na(Movement),!is.na(StringencyIndex))%>%
  #filter(Country=="Germany")%>%
  group_by(Country,COL)%>%
  #summarise(Mean=mean(points))
  summarise(cor_simple=cor.test(StringencyIndex,Movement)$estimate[[1]],
    coef_simple=summary(lm(Movement~StringencyIndex))$coefficients[2,1],
            se_simple=summary(lm(Movement~StringencyIndex))$coefficients[2,2],
    cor_dif=cor.test(DifMove,DifPol)$estimate[[1]],
            n=n())
  #mutate(Country = forcats::fct_reorder(Country, coef))%>%
  #datatable()

com<-merge(df_short,lr.coeffs.covariates,by="Country")

#com<-com%>%
#  filter(se_simple<summary(com$se_simple)[[5]])
#Doesn't help to rid of extremely noisy observations

cor.test(data=com,com$COL,com$LongRunCoeff)
cor.test(data=com,com$COL,com$cor_simple)
cor.test(data=com,com$COL,com$cor_dif)

cor.test(data=com,com$risktaking,com$LongRunCoeff)
cor.test(data=com,com$risktaking,com$cor_simple)
cor.test(data=com,com$risktaking,com$cor_dif)

cor.test(data=com,com$ROL,com$LongRunCoeff)
cor.test(data=com,com$ROL,com$cor_simple)
cor.test(data=com,com$ROL,com$cor_dif) #significance

cor.test(data=com,com$polity2,com$LongRunCoeff)
cor.test(data=com,com$polity2,com$cor_simple)
cor.test(data=com,com$polity2,com$cor_dif)

cor.test(data=com,com$CaseLog,com$LongRunCoeff)
cor.test(data=com,com$CaseLog,com$cor_simple)
cor.test(data=com,com$CaseLog,com$cor_dif)

cor.test(data=com,com$patience,com$LongRunCoeff)
cor.test(data=com,com$patience,com$cor_simple)
cor.test(data=com,com$patience,com$cor_dif)



```

# Potential determinants / covariates of compliance

Below, as usual a couple of scatterplots plotting this measure of compliance against a number of other factors (see axis labels). 

Spoiler: Nothing going on.

```{r covariates, echo=FALSE}
ggplot(lr.coeffs.covariates, aes(LongRunCoeff,polity2)) +
  geom_point() +
  geom_smooth(method=lm, color="darkred", fill="blue") + 
  stat_cor(method = "pearson") +
  theme_bw()

ggplot(lr.coeffs.covariates, aes(LongRunCoeff,risktaking)) +
  geom_point() +
  geom_smooth(method=lm, color="darkred", fill="blue") + 
  stat_cor(method = "pearson") +
  theme_bw()

ggplot(lr.coeffs.covariates, aes(LongRunCoeff,patience)) +
  geom_point() +
  geom_smooth(method=lm, color="darkred", fill="blue") + 
  stat_cor(method = "pearson") +
  theme_bw()

ggplot(lr.coeffs.covariates, aes(LongRunCoeff,ROL)) +
  geom_point() +
  geom_smooth(method=lm, color="darkred", fill="blue") + 
  stat_cor(method = "pearson") +
  theme_bw()



ggplot(lr.coeffs.covariates, aes(LongRunCoeff,GDP.capita)) +
  geom_point() +
  geom_smooth(method=lm, color="darkred", fill="blue") + 
  stat_cor(method = "pearson") +
  theme_bw()
ggplot(lr.coeffs.covariates, aes(LongRunCoeff,CaseLog)) +
  geom_point() +
  geom_smooth(method=lm, color="darkred", fill="blue") + 
  stat_cor(method = "pearson") +
  theme_bw()
